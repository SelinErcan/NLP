{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "181041015_NLP_HW4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SelinErcan/NLP/blob/main/sentiment_analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coZKFfE-8WUJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81d21c0a-5ab1-433b-ee14-60cd13b9a1d9"
      },
      "source": [
        "!pip install word2vec-keras\n",
        "!pip install mlflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: word2vec-keras in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from word2vec-keras) (2.2.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from word2vec-keras) (1.15.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from word2vec-keras) (3.6.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from word2vec-keras) (0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from word2vec-keras) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from word2vec-keras) (1.17.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->word2vec-keras) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->word2vec-keras) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->word2vec-keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->word2vec-keras) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->word2vec-keras) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->word2vec-keras) (1.4.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->word2vec-keras) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->word2vec-keras) (0.33.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->word2vec-keras) (3.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->word2vec-keras) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->word2vec-keras) (0.1.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->word2vec-keras) (0.8.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->word2vec-keras) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->word2vec-keras) (1.11.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->word2vec-keras) (0.9.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->word2vec-keras) (1.15.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->word2vec-keras) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->word2vec-keras) (3.10.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->word2vec-keras) (1.9.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->word2vec-keras) (0.22.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow->word2vec-keras) (42.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow->word2vec-keras) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow->word2vec-keras) (0.16.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->word2vec-keras) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->word2vec-keras) (1.10.47)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->word2vec-keras) (2.21.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->word2vec-keras) (0.14.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->word2vec-keras) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->word2vec-keras) (1.13.47)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->word2vec-keras) (0.2.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim->word2vec-keras) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim->word2vec-keras) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim->word2vec-keras) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim->word2vec-keras) (2.8)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->smart-open>=1.2.1->gensim->word2vec-keras) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->smart-open>=1.2.1->gensim->word2vec-keras) (2.6.1)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
            "Requirement already satisfied: databricks-cli>=0.8.7 in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.17.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.12.0)\n",
            "Requirement already satisfied: gunicorn; platform_system != \"Windows\" in /usr/local/lib/python3.6/dist-packages (from mlflow) (20.0.4)\n",
            "Requirement already satisfied: docker>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (4.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow) (3.13)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.3.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from mlflow) (2.6.1)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.3.2)\n",
            "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.6/dist-packages (from mlflow) (2.21.0)\n",
            "Requirement already satisfied: prometheus-flask-exporter in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.12.1)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.1.1)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.6/dist-packages (from mlflow) (3.17.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.25.3)\n",
            "Requirement already satisfied: gitpython>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (3.0.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.3)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.3.12)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow) (7.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: gorilla in /usr/local/lib/python3.6/dist-packages (from mlflow) (0.3.0)\n",
            "Requirement already satisfied: querystring-parser in /usr/local/lib/python3.6/dist-packages (from mlflow) (1.2.4)\n",
            "Requirement already satisfied: configparser>=0.3.5 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow) (4.0.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow) (0.8.6)\n",
            "Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.6/dist-packages (from gunicorn; platform_system != \"Windows\"->mlflow) (42.0.2)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.6/dist-packages (from docker>=4.0.0->mlflow) (0.57.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.6/dist-packages (from alembic->mlflow) (1.1.0)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.6/dist-packages (from alembic->mlflow) (1.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.6/dist-packages (from prometheus-flask-exporter->mlflow) (0.7.1)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (0.16.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow) (2.10.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->mlflow) (2018.9)\n",
            "Requirement already satisfied: gitdb2>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from gitpython>=2.1.0->mlflow) (2.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->mlflow) (1.1.1)\n",
            "Requirement already satisfied: smmap2>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from gitdb2>=2.0.0->gitpython>=2.1.0->mlflow) (2.0.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxyr-DM299Uv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "b3c4efad-7c10-41cf-b1b0-5da5b975358a"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from word2vec_keras import Word2VecKeras\n",
        "from pprint import pprint\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "import ast # abstract syntax tree: https://docs.python.org/3/library/ast.html\n",
        "from sklearn.model_selection import train_test_split\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "import io\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf \n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVS-m6IX99U9"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJm-GPVU99U_"
      },
      "source": [
        "class Preprocessing(object):\n",
        "    def __init__(self, data, target_column_name='body_text_clean'):\n",
        "        self.data = data\n",
        "        self.feature_name = target_column_name\n",
        "        \n",
        "    def remove_punctuation(self, text):\n",
        "        # string.punctuation: '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
        "        text_nopunct = \"\".join([char for char in text if char not in string.punctuation])# It will discard all punctuations\n",
        "        return text_nopunct\n",
        "    \n",
        "    def tokenize(self, text):\n",
        "        #W+ Matches one or more characters which are not word character.\n",
        "        tokens = re.split(r'\\W+', text) \n",
        "        return tokens\n",
        "    \n",
        "    def remove_stopwords(self, tokenized_list):\n",
        "        '''\n",
        "        download stopwords zip file at: http://www.nltk.org/nltk_data/\n",
        "        move the unzipped directory stopwords to: /Users/yuhuang/anaconda3/envs/deeplearning/nltk_data/corpora\n",
        "        '''\n",
        "        # Remove all English Stopwords\n",
        "        stopword = nltk.corpus.stopwords.words('english')\n",
        "        text = [word for word in tokenized_list if word not in stopword]\n",
        "        return text   \n",
        "\n",
        "    def stemming(self, tokenized_text):\n",
        "        ps = nltk.PorterStemmer()\n",
        "        text = [ps.stem(word) for word in tokenized_text]\n",
        "        return text\n",
        "    \n",
        "    def lemmatizing(self, tokenized_text):\n",
        "        '''\n",
        "        download wordnet at: http://www.nltk.org/nltk_data/\n",
        "        move wprdnet.zip file to: /Users/yuhuang/anaconda3/envs/deeplearning/nltk_data/corpora\n",
        "        '''\n",
        "        wn = nltk.WordNetLemmatizer()\n",
        "        text = [wn.lemmatize(word) for word in tokenized_text]\n",
        "        return text\n",
        "    \n",
        "    def tokens_to_string(self, tokens_string):\n",
        "        try:\n",
        "            list_obj = ast.literal_eval(tokens_string)\n",
        "            text = \" \".join(list_obj)\n",
        "        except:\n",
        "            text = None\n",
        "        return text\n",
        "    \n",
        "    def dropna(self):\n",
        "        feature_name = self.feature_name\n",
        "        if self.data[feature_name].isnull().sum() > 0:\n",
        "            column_list=[feature_name]\n",
        "            self.data = self.data.dropna(subset=column_list)\n",
        "            return self.data\n",
        "        \n",
        "    def preprocessing(self, feature):\n",
        "        self.data['body_text_nopunc'] = self.data['body_text'].apply(lambda x: self.remove_punctuation(x))\n",
        "        self.data['body_text_tokenized'] = self.data['body_text_nopunc'].apply(lambda x: self.tokenize(x.lower())) \n",
        "        self.data['body_text_nostop'] = self.data['body_text_tokenized'].apply(lambda x: self.remove_stopwords(x))\n",
        "        self.data['body_text_stemmed'] = self.data['body_text_nostop'].apply(lambda x: self.stemming(x))\n",
        "        self.data['body_text_lemmatized'] = self.data['body_text_nostop'].apply(lambda x: self.lemmatizing(x))\n",
        "\n",
        "        # save cleaned dataset into csv file and load back\n",
        "        self.save()\n",
        "        self.load()\n",
        "        \n",
        "        self.data[self.feature_name] = self.data['body_text_lemmatized'].apply(lambda x: self.tokens_to_string(x))\n",
        "        \n",
        "        self.dropna() # error occurred!!!\n",
        "\n",
        "        drop_non_featured = ''\n",
        "        if feature == 'body_text':\n",
        "          drop_non_featured = 'body_text_clean'\n",
        "        else:\n",
        "          drop_non_featured = 'body_text'\n",
        "\n",
        "        drop_columns = ['body_text_nopunc', 'body_text_tokenized', 'body_text_nostop', 'body_text_stemmed', 'body_text_lemmatized', drop_non_featured] \n",
        "        self.data.drop(drop_columns, axis=1, inplace=True)\n",
        "        \n",
        "        \n",
        "        return self.data\n",
        "    \n",
        "    def save(self, filepath=\"sentiment_cleaned.csv\"):\n",
        "        self.data.to_csv(filepath, index=False, sep=',')  \n",
        "        \n",
        "    def load(self, filepath=\"sentiment_cleaned.csv\"):\n",
        "        self.data = pd.read_csv(filepath)\n",
        "        return self.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCZ-7Ags99VF"
      },
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1nL__7s99VH"
      },
      "source": [
        "class SentimentAnalyzer(object):\n",
        "    def __init__(self):\n",
        "        self.model = Word2VecKeras()\n",
        "        \n",
        "    def load_data(self):\n",
        "        '''\n",
        "        Changed for sentiment analysis\n",
        "        '''\n",
        "        file_positive = 'gdrive/My Drive/Positive_RAW.txt'\n",
        "        file_negative = 'gdrive/My Drive/Negative_RAW.txt'\n",
        "        positive_data = []\n",
        "        negative_data = []\n",
        "        with open(file_positive) as file_positive:\n",
        "          for line in file_positive:\n",
        "            positive_data.append([\"positive\",line])\n",
        "        with open(file_negative) as file_negative:\n",
        "          for line in file_negative:\n",
        "            negative_data.append([\"negative\",line])\n",
        "\n",
        "        positive_df = pd.DataFrame(positive_data, columns =['label', 'body_text']) \n",
        "        negative_df = pd.DataFrame(negative_data, columns =['label', 'body_text'])\n",
        "\n",
        "        df=positive_df.append(negative_df, ignore_index=True)\n",
        "        self.raw_data = df.sample(frac=1.0) \n",
        "        \n",
        "        print('Rows: {}, Columns: {}'.format(self.raw_data.shape[0], self.raw_data.shape[1]))\n",
        "        print(\"Total rows: {}, positive: {}, negative: {}\".format(len(self.raw_data),\n",
        "                                                       len(self.raw_data[self.raw_data['label']=='positive']),\n",
        "                                                       len(self.raw_data[self.raw_data['label']=='negative'])))\n",
        "        \n",
        "        print(\"Total number of missing labels: {}\".format(self.raw_data['label'].isnull().sum()))\n",
        "        print(\"Total number of missging text: {}\".format(self.raw_data['body_text'].isnull().sum()))\n",
        "\n",
        "        return self.raw_data\n",
        "    \n",
        "    def split_data(self):\n",
        "        # Shuffle and split the data into training and testing subsets\n",
        "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.x, self.y, test_size=0.25, random_state=42)\n",
        "        \n",
        "    def numpy_to_list(self):\n",
        "        '''\n",
        "        convert Numpy ndarray to Python list for word2vec-keras API\n",
        "        '''\n",
        "        self.x_train = self.x_train.tolist()\n",
        "        self.y_train = self.y_train.tolist()\n",
        "        self.x_test  = self.x_test.tolist()\n",
        "        self.y_test  = self.y_test.tolist()\n",
        "    \n",
        "    def prepare_data(self, feature, label='label'):\n",
        "        self.load_data()\n",
        "        pp = Preprocessing(self.raw_data)\n",
        "        self.data = pp.preprocessing(feature)\n",
        "        \n",
        "        print('self.data[feture] type: ', type(self.data))\n",
        "        \n",
        "        self.x = self.data[feature].values\n",
        "        self.y = self.data[label].values\n",
        "        self.split_data()\n",
        "        self.numpy_to_list()\n",
        "        \n",
        "        print(self.data)\n",
        "        return self.data\n",
        "        \n",
        "    def train_model(self):\n",
        "        '''\n",
        "        w2v_min_count\n",
        "        \n",
        "        RuntimeError: you must first build vocabulary before training the model.\n",
        "        \n",
        "        You configured a min_count of 50 (-m 50), but maybe there is no word in \n",
        "        your vocabulary with frequency greater than 50, hence your vocab will be empty and \n",
        "        gensim returns the error. Try a lower min_count ...\n",
        "        '''\n",
        "        self.w2v_size = 300\n",
        "        self.w2v_min_count = 1 # 5\n",
        "        self.w2v_epochs = 100\n",
        "        self.k_epochs = 5 # 32\n",
        "        self.k_lstm_neurons = 512\n",
        "        self.k_max_sequence_len = 1000\n",
        "        \n",
        "        self.model.train(self.x_train, self.y_train, \n",
        "            w2v_size=self.w2v_size, \n",
        "            w2v_min_count=self.w2v_min_count, \n",
        "            w2v_epochs=self.w2v_epochs, \n",
        "            k_epochs=self.k_epochs, \n",
        "            k_lstm_neurons=self.k_lstm_neurons, \n",
        "            k_max_sequence_len=self.k_max_sequence_len, \n",
        "            k_hidden_layer_neurons=[])\n",
        "        \n",
        "    def evaluate(self):\n",
        "        self.result = self.model.evaluate(self.x_test, self.y_test)\n",
        "        self.accuracy = self.result[\"ACCURACY\"]\n",
        "        self.clf_report_df = pd.DataFrame(self.result[\"CLASSIFICATION_REPORT\"])\n",
        "        self.cnf_matrix = self.result[\"CONFUSION_MATRIX\"]\n",
        "        print('Confusion Matrix: ', self.cnf_matrix)\n",
        "        return self.result\n",
        "    \n",
        "    def predict(self, idx=1):\n",
        "        print(\"LABEL:\", self.y_test[idx])\n",
        "        print(\"TEXT :\", self.x_test[idx])\n",
        "        print(\"/n============================================\")\n",
        "        print(\"PREDICTION:\", self.model.predict(self.x_test[idx]))\n",
        "        \n",
        "    def mlFlow(self, feature='body_text_clean'):\n",
        "        np.random.seed(40)  \n",
        "        with mlflow.start_run():\n",
        "            self.prepare_data(feature=feature) # feature should be 'body_text' if no need to preprocessing\n",
        "            self.train_model()\n",
        "            self.evaluate()\n",
        "            self.predict()\n",
        "            mlflow.log_param(\"feature\", feature) \n",
        "            mlflow.log_param(\"w2v_size\", self.w2v_size)  \n",
        "            mlflow.log_param(\"w2v_min_count\", self.w2v_min_count)\n",
        "            mlflow.log_param(\"w2v_epochs\", self.w2v_epochs)\n",
        "            mlflow.log_param(\"k_lstm_neurons\", self.k_lstm_neurons)\n",
        "            mlflow.log_param(\"k_max_sequence_len\", self.k_max_sequence_len)\n",
        "            mlflow.log_metric(\"accuracy\", self.accuracy)\n",
        "            mlflow.sklearn.log_model(self.model, \"Word2Vec-Keras\")\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-Ps8UW4DnM0"
      },
      "source": [
        "## No Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcH8f4oQ99VS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cf66262e-4a91-4d9a-e5a4-4bf5b3241b3a"
      },
      "source": [
        "sentiment_clf_np = SentimentAnalyzer()\n",
        "sentiment_clf_np.mlFlow(feature='body_text')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rows: 10655, Columns: 2\n",
            "Total rows: 10655, positive: 5327, negative: 5328\n",
            "Total number of missing labels: 0\n",
            "Total number of missging text: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-16 07:39:45,891 : INFO : Build & train Word2Vec model\n",
            "2020-01-16 07:39:45,893 : INFO : collecting all words and their counts\n",
            "2020-01-16 07:39:45,894 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self.data[feture] type:  <class 'pandas.core.frame.DataFrame'>\n",
            "          label                                          body_text\n",
            "0      positive    benim çok nadirdir bir filmi birden fazla iz...\n",
            "1      positive    harika bir klasik.ayrica filmin sonlarinda k...\n",
            "2      positive    sanilanin aksime türkçe düblajla da gayet gü...\n",
            "3      negative    lütfen gitmeyin paraniz ve zamaniniz yaninda...\n",
            "4      positive    siki bir film.meraklilarina tavsiye ederim.....\n",
            "...         ...                                                ...\n",
            "10650  negative    ne oyunlar döndügünü güzel anlatiyor. filme ...\n",
            "10651  positive    kimseyi bilmem ama bnm psikolojim bozuldu ya...\n",
            "10652  negative    hayatimda sinemada izledigim en igrenç film,...\n",
            "10653  negative     yazik yazik,imdb top 100 de 1. sirada!sinem...\n",
            "10654  negative    bir sinemada bukadar sikilip daraldigimi hat...\n",
            "\n",
            "[10655 rows x 2 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-16 07:39:45,928 : INFO : collected 24187 word types from a corpus of 158125 raw words and 7991 sentences\n",
            "2020-01-16 07:39:45,929 : INFO : Loading a fresh vocabulary\n",
            "2020-01-16 07:39:45,965 : INFO : effective_min_count=1 retains 24187 unique words (100% of original 24187, drops 0)\n",
            "2020-01-16 07:39:45,965 : INFO : effective_min_count=1 leaves 158125 word corpus (100% of original 158125, drops 0)\n",
            "2020-01-16 07:39:46,030 : INFO : deleting the raw counts dictionary of 24187 items\n",
            "2020-01-16 07:39:46,031 : INFO : sample=0.001 downsamples 39 most-common words\n",
            "2020-01-16 07:39:46,032 : INFO : downsampling leaves estimated 132432 word corpus (83.8% of prior 158125)\n",
            "2020-01-16 07:39:46,071 : INFO : estimated required memory for 24187 words and 300 dimensions: 70142300 bytes\n",
            "2020-01-16 07:39:46,072 : INFO : resetting layer weights\n",
            "2020-01-16 07:39:50,256 : INFO : training model with 2 workers on 24187 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2020-01-16 07:39:50,582 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:50,589 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:50,590 : INFO : EPOCH - 1 : training on 158125 raw words (132424 effective words) took 0.3s, 402866 effective words/s\n",
            "2020-01-16 07:39:50,890 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:50,891 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:50,892 : INFO : EPOCH - 2 : training on 158125 raw words (132517 effective words) took 0.3s, 446433 effective words/s\n",
            "2020-01-16 07:39:51,195 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:51,200 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:51,201 : INFO : EPOCH - 3 : training on 158125 raw words (132477 effective words) took 0.3s, 441113 effective words/s\n",
            "2020-01-16 07:39:51,513 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:51,519 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:51,522 : INFO : EPOCH - 4 : training on 158125 raw words (132414 effective words) took 0.3s, 420816 effective words/s\n",
            "2020-01-16 07:39:51,833 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:51,845 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:51,846 : INFO : EPOCH - 5 : training on 158125 raw words (132418 effective words) took 0.3s, 416793 effective words/s\n",
            "2020-01-16 07:39:52,138 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:52,143 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:52,144 : INFO : EPOCH - 6 : training on 158125 raw words (132467 effective words) took 0.3s, 455218 effective words/s\n",
            "2020-01-16 07:39:52,459 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:52,462 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:52,463 : INFO : EPOCH - 7 : training on 158125 raw words (132251 effective words) took 0.3s, 423170 effective words/s\n",
            "2020-01-16 07:39:52,767 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:52,770 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:52,771 : INFO : EPOCH - 8 : training on 158125 raw words (132403 effective words) took 0.3s, 439922 effective words/s\n",
            "2020-01-16 07:39:53,087 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:53,088 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:53,090 : INFO : EPOCH - 9 : training on 158125 raw words (132412 effective words) took 0.3s, 431106 effective words/s\n",
            "2020-01-16 07:39:53,384 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:53,394 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:53,397 : INFO : EPOCH - 10 : training on 158125 raw words (132515 effective words) took 0.3s, 447466 effective words/s\n",
            "2020-01-16 07:39:53,709 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:53,717 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:53,718 : INFO : EPOCH - 11 : training on 158125 raw words (132503 effective words) took 0.3s, 420854 effective words/s\n",
            "2020-01-16 07:39:54,027 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:54,030 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:54,031 : INFO : EPOCH - 12 : training on 158125 raw words (132549 effective words) took 0.3s, 432872 effective words/s\n",
            "2020-01-16 07:39:54,342 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:54,344 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:54,345 : INFO : EPOCH - 13 : training on 158125 raw words (132430 effective words) took 0.3s, 431582 effective words/s\n",
            "2020-01-16 07:39:54,653 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:54,661 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:54,662 : INFO : EPOCH - 14 : training on 158125 raw words (132426 effective words) took 0.3s, 427236 effective words/s\n",
            "2020-01-16 07:39:54,981 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:54,984 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:54,987 : INFO : EPOCH - 15 : training on 158125 raw words (132482 effective words) took 0.3s, 418134 effective words/s\n",
            "2020-01-16 07:39:55,294 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:55,297 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:55,299 : INFO : EPOCH - 16 : training on 158125 raw words (132375 effective words) took 0.3s, 434706 effective words/s\n",
            "2020-01-16 07:39:55,620 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:55,621 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:55,625 : INFO : EPOCH - 17 : training on 158125 raw words (132288 effective words) took 0.3s, 413686 effective words/s\n",
            "2020-01-16 07:39:55,925 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:55,927 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:55,928 : INFO : EPOCH - 18 : training on 158125 raw words (132500 effective words) took 0.3s, 446370 effective words/s\n",
            "2020-01-16 07:39:56,228 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:56,231 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:56,232 : INFO : EPOCH - 19 : training on 158125 raw words (132266 effective words) took 0.3s, 444951 effective words/s\n",
            "2020-01-16 07:39:56,529 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:56,534 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:56,535 : INFO : EPOCH - 20 : training on 158125 raw words (132242 effective words) took 0.3s, 446523 effective words/s\n",
            "2020-01-16 07:39:56,830 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:56,832 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:56,833 : INFO : EPOCH - 21 : training on 158125 raw words (132495 effective words) took 0.3s, 454627 effective words/s\n",
            "2020-01-16 07:39:57,118 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:57,120 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:57,122 : INFO : EPOCH - 22 : training on 158125 raw words (132439 effective words) took 0.3s, 470428 effective words/s\n",
            "2020-01-16 07:39:57,427 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:57,430 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:57,431 : INFO : EPOCH - 23 : training on 158125 raw words (132381 effective words) took 0.3s, 437464 effective words/s\n",
            "2020-01-16 07:39:57,740 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:57,744 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:57,745 : INFO : EPOCH - 24 : training on 158125 raw words (132510 effective words) took 0.3s, 431410 effective words/s\n",
            "2020-01-16 07:39:58,042 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:58,044 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:58,048 : INFO : EPOCH - 25 : training on 158125 raw words (132382 effective words) took 0.3s, 445138 effective words/s\n",
            "2020-01-16 07:39:58,353 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:58,359 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:58,360 : INFO : EPOCH - 26 : training on 158125 raw words (132460 effective words) took 0.3s, 432862 effective words/s\n",
            "2020-01-16 07:39:58,672 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:58,674 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:58,677 : INFO : EPOCH - 27 : training on 158125 raw words (132420 effective words) took 0.3s, 427046 effective words/s\n",
            "2020-01-16 07:39:58,980 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:58,985 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:58,986 : INFO : EPOCH - 28 : training on 158125 raw words (132316 effective words) took 0.3s, 435640 effective words/s\n",
            "2020-01-16 07:39:59,305 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:59,308 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:59,310 : INFO : EPOCH - 29 : training on 158125 raw words (132435 effective words) took 0.3s, 418234 effective words/s\n",
            "2020-01-16 07:39:59,617 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:59,624 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:59,625 : INFO : EPOCH - 30 : training on 158125 raw words (132506 effective words) took 0.3s, 431261 effective words/s\n",
            "2020-01-16 07:39:59,931 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:39:59,933 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:39:59,934 : INFO : EPOCH - 31 : training on 158125 raw words (132441 effective words) took 0.3s, 437977 effective words/s\n",
            "2020-01-16 07:40:00,221 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:00,223 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:00,225 : INFO : EPOCH - 32 : training on 158125 raw words (132514 effective words) took 0.3s, 465211 effective words/s\n",
            "2020-01-16 07:40:00,525 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:00,531 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:00,532 : INFO : EPOCH - 33 : training on 158125 raw words (132452 effective words) took 0.3s, 438655 effective words/s\n",
            "2020-01-16 07:40:00,835 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:00,845 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:00,846 : INFO : EPOCH - 34 : training on 158125 raw words (132372 effective words) took 0.3s, 430830 effective words/s\n",
            "2020-01-16 07:40:01,144 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:01,146 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:01,147 : INFO : EPOCH - 35 : training on 158125 raw words (132365 effective words) took 0.3s, 453169 effective words/s\n",
            "2020-01-16 07:40:01,467 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:01,472 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:01,474 : INFO : EPOCH - 36 : training on 158125 raw words (132372 effective words) took 0.3s, 414479 effective words/s\n",
            "2020-01-16 07:40:01,789 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:01,794 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:01,795 : INFO : EPOCH - 37 : training on 158125 raw words (132496 effective words) took 0.3s, 429394 effective words/s\n",
            "2020-01-16 07:40:02,081 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:02,084 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:02,085 : INFO : EPOCH - 38 : training on 158125 raw words (132480 effective words) took 0.3s, 467617 effective words/s\n",
            "2020-01-16 07:40:02,379 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:02,384 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:02,385 : INFO : EPOCH - 39 : training on 158125 raw words (132371 effective words) took 0.3s, 455499 effective words/s\n",
            "2020-01-16 07:40:02,695 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:02,700 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:02,701 : INFO : EPOCH - 40 : training on 158125 raw words (132396 effective words) took 0.3s, 435646 effective words/s\n",
            "2020-01-16 07:40:02,991 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:02,994 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:02,995 : INFO : EPOCH - 41 : training on 158125 raw words (132578 effective words) took 0.3s, 460468 effective words/s\n",
            "2020-01-16 07:40:03,281 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:03,288 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:03,289 : INFO : EPOCH - 42 : training on 158125 raw words (132278 effective words) took 0.3s, 459531 effective words/s\n",
            "2020-01-16 07:40:03,577 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:03,580 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:03,582 : INFO : EPOCH - 43 : training on 158125 raw words (132414 effective words) took 0.3s, 461803 effective words/s\n",
            "2020-01-16 07:40:03,897 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:03,899 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:03,902 : INFO : EPOCH - 44 : training on 158125 raw words (132623 effective words) took 0.3s, 423436 effective words/s\n",
            "2020-01-16 07:40:04,198 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:04,200 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:04,203 : INFO : EPOCH - 45 : training on 158125 raw words (132517 effective words) took 0.3s, 449169 effective words/s\n",
            "2020-01-16 07:40:04,517 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:04,522 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:04,522 : INFO : EPOCH - 46 : training on 158125 raw words (132339 effective words) took 0.3s, 422808 effective words/s\n",
            "2020-01-16 07:40:04,842 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:04,845 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:04,846 : INFO : EPOCH - 47 : training on 158125 raw words (132391 effective words) took 0.3s, 419012 effective words/s\n",
            "2020-01-16 07:40:05,134 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:05,139 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:05,139 : INFO : EPOCH - 48 : training on 158125 raw words (132276 effective words) took 0.3s, 461977 effective words/s\n",
            "2020-01-16 07:40:05,429 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:05,433 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:05,434 : INFO : EPOCH - 49 : training on 158125 raw words (132471 effective words) took 0.3s, 460430 effective words/s\n",
            "2020-01-16 07:40:05,738 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:05,745 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:05,745 : INFO : EPOCH - 50 : training on 158125 raw words (132414 effective words) took 0.3s, 439491 effective words/s\n",
            "2020-01-16 07:40:06,043 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:06,045 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:06,047 : INFO : EPOCH - 51 : training on 158125 raw words (132381 effective words) took 0.3s, 447471 effective words/s\n",
            "2020-01-16 07:40:06,348 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:06,353 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:06,354 : INFO : EPOCH - 52 : training on 158125 raw words (132336 effective words) took 0.3s, 440446 effective words/s\n",
            "2020-01-16 07:40:06,655 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:06,657 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:06,658 : INFO : EPOCH - 53 : training on 158125 raw words (132461 effective words) took 0.3s, 443929 effective words/s\n",
            "2020-01-16 07:40:06,954 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:06,960 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:06,961 : INFO : EPOCH - 54 : training on 158125 raw words (132533 effective words) took 0.3s, 445793 effective words/s\n",
            "2020-01-16 07:40:07,243 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:07,248 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:07,249 : INFO : EPOCH - 55 : training on 158125 raw words (132549 effective words) took 0.3s, 471763 effective words/s\n",
            "2020-01-16 07:40:07,549 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:07,554 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:07,555 : INFO : EPOCH - 56 : training on 158125 raw words (132370 effective words) took 0.3s, 440726 effective words/s\n",
            "2020-01-16 07:40:07,853 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:07,862 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:07,865 : INFO : EPOCH - 57 : training on 158125 raw words (132352 effective words) took 0.3s, 436372 effective words/s\n",
            "2020-01-16 07:40:08,161 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:08,172 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:08,173 : INFO : EPOCH - 58 : training on 158125 raw words (132356 effective words) took 0.3s, 438420 effective words/s\n",
            "2020-01-16 07:40:08,461 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:08,463 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:08,464 : INFO : EPOCH - 59 : training on 158125 raw words (132386 effective words) took 0.3s, 465472 effective words/s\n",
            "2020-01-16 07:40:08,769 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:08,776 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:08,778 : INFO : EPOCH - 60 : training on 158125 raw words (132321 effective words) took 0.3s, 432115 effective words/s\n",
            "2020-01-16 07:40:09,068 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:09,070 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:09,071 : INFO : EPOCH - 61 : training on 158125 raw words (132402 effective words) took 0.3s, 463696 effective words/s\n",
            "2020-01-16 07:40:09,370 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:09,372 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:09,373 : INFO : EPOCH - 62 : training on 158125 raw words (132439 effective words) took 0.3s, 450477 effective words/s\n",
            "2020-01-16 07:40:09,655 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:09,657 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:09,658 : INFO : EPOCH - 63 : training on 158125 raw words (132488 effective words) took 0.3s, 476964 effective words/s\n",
            "2020-01-16 07:40:09,954 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:09,957 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:09,958 : INFO : EPOCH - 64 : training on 158125 raw words (132147 effective words) took 0.3s, 451373 effective words/s\n",
            "2020-01-16 07:40:10,257 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:10,265 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:10,266 : INFO : EPOCH - 65 : training on 158125 raw words (132408 effective words) took 0.3s, 439586 effective words/s\n",
            "2020-01-16 07:40:10,558 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:10,561 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:10,563 : INFO : EPOCH - 66 : training on 158125 raw words (132353 effective words) took 0.3s, 455410 effective words/s\n",
            "2020-01-16 07:40:10,869 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:10,871 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:10,873 : INFO : EPOCH - 67 : training on 158125 raw words (132404 effective words) took 0.3s, 435465 effective words/s\n",
            "2020-01-16 07:40:11,181 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:11,188 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:11,190 : INFO : EPOCH - 68 : training on 158125 raw words (132372 effective words) took 0.3s, 428202 effective words/s\n",
            "2020-01-16 07:40:11,482 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:11,487 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:11,488 : INFO : EPOCH - 69 : training on 158125 raw words (132580 effective words) took 0.3s, 454065 effective words/s\n",
            "2020-01-16 07:40:11,791 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:11,797 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:11,798 : INFO : EPOCH - 70 : training on 158125 raw words (132503 effective words) took 0.3s, 435447 effective words/s\n",
            "2020-01-16 07:40:12,098 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:12,108 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:12,109 : INFO : EPOCH - 71 : training on 158125 raw words (132265 effective words) took 0.3s, 434194 effective words/s\n",
            "2020-01-16 07:40:12,393 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:12,395 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:12,396 : INFO : EPOCH - 72 : training on 158125 raw words (132265 effective words) took 0.3s, 471912 effective words/s\n",
            "2020-01-16 07:40:12,682 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:12,688 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:12,689 : INFO : EPOCH - 73 : training on 158125 raw words (132444 effective words) took 0.3s, 464494 effective words/s\n",
            "2020-01-16 07:40:12,988 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:12,994 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:12,995 : INFO : EPOCH - 74 : training on 158125 raw words (132399 effective words) took 0.3s, 442235 effective words/s\n",
            "2020-01-16 07:40:13,287 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:13,289 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:13,290 : INFO : EPOCH - 75 : training on 158125 raw words (132486 effective words) took 0.3s, 457203 effective words/s\n",
            "2020-01-16 07:40:13,578 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:13,585 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:13,586 : INFO : EPOCH - 76 : training on 158125 raw words (132390 effective words) took 0.3s, 460731 effective words/s\n",
            "2020-01-16 07:40:13,877 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:13,886 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:13,887 : INFO : EPOCH - 77 : training on 158125 raw words (132410 effective words) took 0.3s, 448438 effective words/s\n",
            "2020-01-16 07:40:14,172 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:14,181 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:14,182 : INFO : EPOCH - 78 : training on 158125 raw words (132219 effective words) took 0.3s, 457994 effective words/s\n",
            "2020-01-16 07:40:14,493 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:14,503 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:14,504 : INFO : EPOCH - 79 : training on 158125 raw words (132627 effective words) took 0.3s, 422279 effective words/s\n",
            "2020-01-16 07:40:14,779 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:14,784 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:14,785 : INFO : EPOCH - 80 : training on 158125 raw words (132491 effective words) took 0.3s, 481208 effective words/s\n",
            "2020-01-16 07:40:15,093 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:15,094 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:15,095 : INFO : EPOCH - 81 : training on 158125 raw words (132375 effective words) took 0.3s, 435347 effective words/s\n",
            "2020-01-16 07:40:15,407 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:15,412 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:15,413 : INFO : EPOCH - 82 : training on 158125 raw words (132452 effective words) took 0.3s, 424224 effective words/s\n",
            "2020-01-16 07:40:15,697 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:15,705 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:15,706 : INFO : EPOCH - 83 : training on 158125 raw words (132611 effective words) took 0.3s, 462454 effective words/s\n",
            "2020-01-16 07:40:16,006 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:16,012 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:16,013 : INFO : EPOCH - 84 : training on 158125 raw words (132513 effective words) took 0.3s, 441931 effective words/s\n",
            "2020-01-16 07:40:16,299 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:16,303 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:16,304 : INFO : EPOCH - 85 : training on 158125 raw words (132373 effective words) took 0.3s, 465579 effective words/s\n",
            "2020-01-16 07:40:16,594 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:16,598 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:16,599 : INFO : EPOCH - 86 : training on 158125 raw words (132492 effective words) took 0.3s, 459839 effective words/s\n",
            "2020-01-16 07:40:16,882 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:16,885 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:16,886 : INFO : EPOCH - 87 : training on 158125 raw words (132514 effective words) took 0.3s, 471550 effective words/s\n",
            "2020-01-16 07:40:17,180 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:17,185 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:17,187 : INFO : EPOCH - 88 : training on 158125 raw words (132578 effective words) took 0.3s, 451729 effective words/s\n",
            "2020-01-16 07:40:17,472 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:17,478 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:17,479 : INFO : EPOCH - 89 : training on 158125 raw words (132373 effective words) took 0.3s, 461898 effective words/s\n",
            "2020-01-16 07:40:17,790 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:17,794 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:17,795 : INFO : EPOCH - 90 : training on 158125 raw words (132324 effective words) took 0.3s, 427162 effective words/s\n",
            "2020-01-16 07:40:18,086 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:18,090 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:18,092 : INFO : EPOCH - 91 : training on 158125 raw words (132369 effective words) took 0.3s, 458554 effective words/s\n",
            "2020-01-16 07:40:18,380 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:18,385 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:18,385 : INFO : EPOCH - 92 : training on 158125 raw words (132370 effective words) took 0.3s, 461262 effective words/s\n",
            "2020-01-16 07:40:18,664 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:18,667 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:18,669 : INFO : EPOCH - 93 : training on 158125 raw words (132541 effective words) took 0.3s, 478846 effective words/s\n",
            "2020-01-16 07:40:18,959 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:18,962 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:18,966 : INFO : EPOCH - 94 : training on 158125 raw words (132322 effective words) took 0.3s, 455580 effective words/s\n",
            "2020-01-16 07:40:19,261 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:19,272 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:19,272 : INFO : EPOCH - 95 : training on 158125 raw words (132434 effective words) took 0.3s, 438591 effective words/s\n",
            "2020-01-16 07:40:19,564 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:19,566 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:19,568 : INFO : EPOCH - 96 : training on 158125 raw words (132232 effective words) took 0.3s, 457418 effective words/s\n",
            "2020-01-16 07:40:19,854 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:19,856 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:19,857 : INFO : EPOCH - 97 : training on 158125 raw words (132541 effective words) took 0.3s, 466502 effective words/s\n",
            "2020-01-16 07:40:20,147 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:20,152 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:20,153 : INFO : EPOCH - 98 : training on 158125 raw words (132386 effective words) took 0.3s, 459371 effective words/s\n",
            "2020-01-16 07:40:20,442 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:20,445 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:20,446 : INFO : EPOCH - 99 : training on 158125 raw words (132352 effective words) took 0.3s, 461873 effective words/s\n",
            "2020-01-16 07:40:20,750 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:40:20,757 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:40:20,758 : INFO : EPOCH - 100 : training on 158125 raw words (132488 effective words) took 0.3s, 434518 effective words/s\n",
            "2020-01-16 07:40:20,759 : INFO : training on a 15812500 raw words (13242040 effective words) took 30.5s, 434132 effective words/s\n",
            "2020-01-16 07:40:20,761 : INFO : Vocabulary size: 24187\n",
            "2020-01-16 07:40:20,762 : INFO : Word2Vec trained\n",
            "2020-01-16 07:40:20,763 : INFO : Fit LabelEncoder\n",
            "2020-01-16 07:40:20,767 : INFO : Fit Tokenizer\n",
            "2020-01-16 07:40:21,016 : INFO : Number of unique words: 24188\n",
            "2020-01-16 07:40:21,017 : INFO : Create Embedding matrix\n",
            "2020-01-16 07:40:25,413 : INFO : Embedding matrix: (24188, 300)\n",
            "2020-01-16 07:40:25,414 : INFO : Build Keras model\n",
            "2020-01-16 07:40:25,417 : INFO : x_train shape: (7991, 1000)\n",
            "2020-01-16 07:40:25,418 : INFO : y_train shape: (7991, 2)\n",
            "2020-01-16 07:40:26,837 : INFO : None\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1335: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n",
            "2020-01-16 07:40:26,839 : INFO : Fit Keras model\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 1000, 300)         7256400   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 512)               1665024   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 8,922,450\n",
            "Trainable params: 1,666,050\n",
            "Non-trainable params: 7,256,400\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "7991/7991 [==============================] - 89s 11ms/step - loss: 0.3926 - acc: 0.8289\n",
            "Epoch 2/5\n",
            "7991/7991 [==============================] - 88s 11ms/step - loss: 0.3075 - acc: 0.8681\n",
            "Epoch 3/5\n",
            "7991/7991 [==============================] - 88s 11ms/step - loss: 0.2652 - acc: 0.8898\n",
            "Epoch 4/5\n",
            "7991/7991 [==============================] - 88s 11ms/step - loss: 0.2895 - acc: 0.8795\n",
            "Epoch 5/5\n",
            "7991/7991 [==============================] - 88s 11ms/step - loss: 0.3325 - acc: 0.8535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-16 07:47:48,665 : INFO : Done\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2664/2664 [==============================] - 48s 18ms/step\n",
            "Confusion Matrix:  [[1173  174]\n",
            " [ 153 1164]]\n",
            "LABEL: negative\n",
            "TEXT :    ilk filmden daha kötu hayal kirikligina ugradim. \n",
            "\n",
            "/n============================================\n",
            "PREDICTION: {'label': 'negative', 'confidence': 0.6220336556434631, 'elapsed_time': 0.568145751953125}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL_qLjpdDtnV"
      },
      "source": [
        "## Preprocessed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3EeISyfDi98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5648780-4120-43d2-db2c-710e69938320"
      },
      "source": [
        "sentiment_clf = SentimentAnalyzer()\n",
        "sentiment_clf.mlFlow()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rows: 10655, Columns: 2\n",
            "Total rows: 10655, positive: 5327, negative: 5328\n",
            "Total number of missing labels: 0\n",
            "Total number of missging text: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-16 07:48:44,959 : INFO : Build & train Word2Vec model\n",
            "2020-01-16 07:48:44,960 : INFO : collecting all words and their counts\n",
            "2020-01-16 07:48:44,961 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2020-01-16 07:48:44,992 : INFO : collected 27250 word types from a corpus of 146670 raw words and 7991 sentences\n",
            "2020-01-16 07:48:44,992 : INFO : Loading a fresh vocabulary\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self.data[feture] type:  <class 'pandas.core.frame.DataFrame'>\n",
            "          label                                    body_text_clean\n",
            "0      positive   benim çok nadirdir bir filmi birden fazla izl...\n",
            "1      positive   harika bir klasikayrica filmin sonlarinda küç...\n",
            "2      positive   sanilanin aksime türkçe düblajla da gayet güz...\n",
            "3      negative   lütfen gitmeyin paraniz zamaniniz yaninda sin...\n",
            "4      positive         siki bir filmmeraklilarina tavsiye ederim \n",
            "...         ...                                                ...\n",
            "10650  negative   ne oyunlar döndügünü güzel anlatiyor filme gü...\n",
            "10651  positive   kimseyi bilmem ama bnm psikolojim bozuldu ya ...\n",
            "10652  negative   hayatimda sinemada izledigim en igrenç film h...\n",
            "10653  negative   yazik yazikimdb top 100 de 1 siradasinema sev...\n",
            "10654  negative   bir sinemada bukadar sikilip daraldigimi hati...\n",
            "\n",
            "[10655 rows x 2 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-16 07:48:45,032 : INFO : effective_min_count=1 retains 27250 unique words (100% of original 27250, drops 0)\n",
            "2020-01-16 07:48:45,033 : INFO : effective_min_count=1 leaves 146670 word corpus (100% of original 146670, drops 0)\n",
            "2020-01-16 07:48:45,098 : INFO : deleting the raw counts dictionary of 27250 items\n",
            "2020-01-16 07:48:45,099 : INFO : sample=0.001 downsamples 36 most-common words\n",
            "2020-01-16 07:48:45,100 : INFO : downsampling leaves estimated 124110 word corpus (84.6% of prior 146670)\n",
            "2020-01-16 07:48:45,145 : INFO : estimated required memory for 27250 words and 300 dimensions: 79025000 bytes\n",
            "2020-01-16 07:48:45,146 : INFO : resetting layer weights\n",
            "2020-01-16 07:48:49,785 : INFO : training model with 2 workers on 27250 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2020-01-16 07:48:50,044 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:50,059 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:50,059 : INFO : EPOCH - 1 : training on 146670 raw words (124047 effective words) took 0.3s, 463141 effective words/s\n",
            "2020-01-16 07:48:50,324 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:50,339 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:50,340 : INFO : EPOCH - 2 : training on 146670 raw words (124025 effective words) took 0.3s, 453957 effective words/s\n",
            "2020-01-16 07:48:50,613 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:50,627 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:50,628 : INFO : EPOCH - 3 : training on 146670 raw words (124059 effective words) took 0.3s, 440400 effective words/s\n",
            "2020-01-16 07:48:50,907 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:50,925 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:50,926 : INFO : EPOCH - 4 : training on 146670 raw words (124036 effective words) took 0.3s, 431027 effective words/s\n",
            "2020-01-16 07:48:51,193 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:51,207 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:51,208 : INFO : EPOCH - 5 : training on 146670 raw words (124010 effective words) took 0.3s, 449371 effective words/s\n",
            "2020-01-16 07:48:51,473 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:51,489 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:51,490 : INFO : EPOCH - 6 : training on 146670 raw words (124142 effective words) took 0.3s, 452654 effective words/s\n",
            "2020-01-16 07:48:51,767 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:51,779 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:51,780 : INFO : EPOCH - 7 : training on 146670 raw words (123901 effective words) took 0.3s, 437441 effective words/s\n",
            "2020-01-16 07:48:52,049 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:52,062 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:52,063 : INFO : EPOCH - 8 : training on 146670 raw words (123996 effective words) took 0.3s, 447258 effective words/s\n",
            "2020-01-16 07:48:52,327 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:52,343 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:52,343 : INFO : EPOCH - 9 : training on 146670 raw words (124050 effective words) took 0.3s, 452241 effective words/s\n",
            "2020-01-16 07:48:52,620 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:52,638 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:52,639 : INFO : EPOCH - 10 : training on 146670 raw words (124056 effective words) took 0.3s, 428812 effective words/s\n",
            "2020-01-16 07:48:52,918 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:52,933 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:52,934 : INFO : EPOCH - 11 : training on 146670 raw words (124130 effective words) took 0.3s, 430602 effective words/s\n",
            "2020-01-16 07:48:53,201 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:53,211 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:53,212 : INFO : EPOCH - 12 : training on 146670 raw words (124173 effective words) took 0.3s, 458743 effective words/s\n",
            "2020-01-16 07:48:53,477 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:53,492 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:53,493 : INFO : EPOCH - 13 : training on 146670 raw words (124146 effective words) took 0.3s, 453627 effective words/s\n",
            "2020-01-16 07:48:53,756 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:53,770 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:53,771 : INFO : EPOCH - 14 : training on 146670 raw words (124145 effective words) took 0.3s, 457461 effective words/s\n",
            "2020-01-16 07:48:54,040 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:54,055 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:54,056 : INFO : EPOCH - 15 : training on 146670 raw words (123979 effective words) took 0.3s, 449907 effective words/s\n",
            "2020-01-16 07:48:54,324 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:54,340 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:54,341 : INFO : EPOCH - 16 : training on 146670 raw words (124172 effective words) took 0.3s, 446925 effective words/s\n",
            "2020-01-16 07:48:54,606 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:54,618 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:54,619 : INFO : EPOCH - 17 : training on 146670 raw words (124225 effective words) took 0.3s, 457862 effective words/s\n",
            "2020-01-16 07:48:54,880 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:54,898 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:54,899 : INFO : EPOCH - 18 : training on 146670 raw words (124163 effective words) took 0.3s, 454457 effective words/s\n",
            "2020-01-16 07:48:55,169 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:55,185 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:55,186 : INFO : EPOCH - 19 : training on 146670 raw words (124221 effective words) took 0.3s, 441553 effective words/s\n",
            "2020-01-16 07:48:55,452 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:55,467 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:55,468 : INFO : EPOCH - 20 : training on 146670 raw words (124137 effective words) took 0.3s, 451005 effective words/s\n",
            "2020-01-16 07:48:55,733 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:55,747 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:55,748 : INFO : EPOCH - 21 : training on 146670 raw words (124161 effective words) took 0.3s, 453974 effective words/s\n",
            "2020-01-16 07:48:56,030 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:56,041 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:56,042 : INFO : EPOCH - 22 : training on 146670 raw words (123991 effective words) took 0.3s, 431140 effective words/s\n",
            "2020-01-16 07:48:56,309 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:56,324 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:56,325 : INFO : EPOCH - 23 : training on 146670 raw words (124291 effective words) took 0.3s, 448576 effective words/s\n",
            "2020-01-16 07:48:56,580 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:56,594 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:56,595 : INFO : EPOCH - 24 : training on 146670 raw words (124065 effective words) took 0.3s, 469974 effective words/s\n",
            "2020-01-16 07:48:56,850 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:56,864 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:56,865 : INFO : EPOCH - 25 : training on 146670 raw words (123966 effective words) took 0.3s, 468942 effective words/s\n",
            "2020-01-16 07:48:57,157 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:57,171 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:57,172 : INFO : EPOCH - 26 : training on 146670 raw words (124117 effective words) took 0.3s, 414882 effective words/s\n",
            "2020-01-16 07:48:57,441 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:57,455 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:57,456 : INFO : EPOCH - 27 : training on 146670 raw words (124084 effective words) took 0.3s, 445140 effective words/s\n",
            "2020-01-16 07:48:57,733 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:57,755 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:57,756 : INFO : EPOCH - 28 : training on 146670 raw words (124100 effective words) took 0.3s, 423272 effective words/s\n",
            "2020-01-16 07:48:58,064 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:58,076 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:58,077 : INFO : EPOCH - 29 : training on 146670 raw words (124160 effective words) took 0.3s, 402746 effective words/s\n",
            "2020-01-16 07:48:58,337 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:58,352 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:58,353 : INFO : EPOCH - 30 : training on 146670 raw words (124025 effective words) took 0.3s, 460800 effective words/s\n",
            "2020-01-16 07:48:58,613 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:58,629 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:58,630 : INFO : EPOCH - 31 : training on 146670 raw words (124057 effective words) took 0.3s, 457899 effective words/s\n",
            "2020-01-16 07:48:58,884 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:58,898 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:58,899 : INFO : EPOCH - 32 : training on 146670 raw words (124304 effective words) took 0.3s, 471651 effective words/s\n",
            "2020-01-16 07:48:59,212 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:59,228 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:59,229 : INFO : EPOCH - 33 : training on 146670 raw words (124261 effective words) took 0.3s, 383147 effective words/s\n",
            "2020-01-16 07:48:59,490 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:59,504 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:59,505 : INFO : EPOCH - 34 : training on 146670 raw words (124009 effective words) took 0.3s, 459540 effective words/s\n",
            "2020-01-16 07:48:59,778 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:48:59,796 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:48:59,797 : INFO : EPOCH - 35 : training on 146670 raw words (124055 effective words) took 0.3s, 436212 effective words/s\n",
            "2020-01-16 07:49:00,096 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:00,113 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:00,114 : INFO : EPOCH - 36 : training on 146670 raw words (124139 effective words) took 0.3s, 402415 effective words/s\n",
            "2020-01-16 07:49:00,403 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:00,420 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:00,421 : INFO : EPOCH - 37 : training on 146670 raw words (124183 effective words) took 0.3s, 414008 effective words/s\n",
            "2020-01-16 07:49:00,698 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:00,711 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:00,713 : INFO : EPOCH - 38 : training on 146670 raw words (124061 effective words) took 0.3s, 434404 effective words/s\n",
            "2020-01-16 07:49:00,993 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:01,010 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:01,012 : INFO : EPOCH - 39 : training on 146670 raw words (124196 effective words) took 0.3s, 424161 effective words/s\n",
            "2020-01-16 07:49:01,309 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:01,325 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:01,325 : INFO : EPOCH - 40 : training on 146670 raw words (124145 effective words) took 0.3s, 402539 effective words/s\n",
            "2020-01-16 07:49:01,611 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:01,626 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:01,627 : INFO : EPOCH - 41 : training on 146670 raw words (124198 effective words) took 0.3s, 422031 effective words/s\n",
            "2020-01-16 07:49:01,904 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:01,912 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:01,913 : INFO : EPOCH - 42 : training on 146670 raw words (123992 effective words) took 0.3s, 441264 effective words/s\n",
            "2020-01-16 07:49:02,206 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:02,220 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:02,221 : INFO : EPOCH - 43 : training on 146670 raw words (124129 effective words) took 0.3s, 411889 effective words/s\n",
            "2020-01-16 07:49:02,495 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:02,510 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:02,510 : INFO : EPOCH - 44 : training on 146670 raw words (124208 effective words) took 0.3s, 437578 effective words/s\n",
            "2020-01-16 07:49:02,773 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:02,788 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:02,789 : INFO : EPOCH - 45 : training on 146670 raw words (124021 effective words) took 0.3s, 457356 effective words/s\n",
            "2020-01-16 07:49:03,057 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:03,071 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:03,072 : INFO : EPOCH - 46 : training on 146670 raw words (124042 effective words) took 0.3s, 451943 effective words/s\n",
            "2020-01-16 07:49:03,350 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:03,364 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:03,364 : INFO : EPOCH - 47 : training on 146670 raw words (124205 effective words) took 0.3s, 433632 effective words/s\n",
            "2020-01-16 07:49:03,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:03,646 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:03,647 : INFO : EPOCH - 48 : training on 146670 raw words (124088 effective words) took 0.3s, 450259 effective words/s\n",
            "2020-01-16 07:49:03,915 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:03,931 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:03,931 : INFO : EPOCH - 49 : training on 146670 raw words (124173 effective words) took 0.3s, 445994 effective words/s\n",
            "2020-01-16 07:49:04,223 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:04,239 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:04,240 : INFO : EPOCH - 50 : training on 146670 raw words (124086 effective words) took 0.3s, 411065 effective words/s\n",
            "2020-01-16 07:49:04,529 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:04,544 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:04,545 : INFO : EPOCH - 51 : training on 146670 raw words (124006 effective words) took 0.3s, 416907 effective words/s\n",
            "2020-01-16 07:49:04,826 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:04,838 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:04,839 : INFO : EPOCH - 52 : training on 146670 raw words (124096 effective words) took 0.3s, 430492 effective words/s\n",
            "2020-01-16 07:49:05,111 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:05,121 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:05,122 : INFO : EPOCH - 53 : training on 146670 raw words (124031 effective words) took 0.3s, 447088 effective words/s\n",
            "2020-01-16 07:49:05,400 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:05,416 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:05,417 : INFO : EPOCH - 54 : training on 146670 raw words (124056 effective words) took 0.3s, 427837 effective words/s\n",
            "2020-01-16 07:49:05,687 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:05,706 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:05,707 : INFO : EPOCH - 55 : training on 146670 raw words (124028 effective words) took 0.3s, 436718 effective words/s\n",
            "2020-01-16 07:49:05,969 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:05,982 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:05,983 : INFO : EPOCH - 56 : training on 146670 raw words (124245 effective words) took 0.3s, 460790 effective words/s\n",
            "2020-01-16 07:49:06,255 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:06,271 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:06,272 : INFO : EPOCH - 57 : training on 146670 raw words (124005 effective words) took 0.3s, 446686 effective words/s\n",
            "2020-01-16 07:49:06,548 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:06,562 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:06,563 : INFO : EPOCH - 58 : training on 146670 raw words (124092 effective words) took 0.3s, 436938 effective words/s\n",
            "2020-01-16 07:49:06,816 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:06,830 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:06,830 : INFO : EPOCH - 59 : training on 146670 raw words (124061 effective words) took 0.3s, 473477 effective words/s\n",
            "2020-01-16 07:49:07,095 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:07,108 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:07,109 : INFO : EPOCH - 60 : training on 146670 raw words (124233 effective words) took 0.3s, 457066 effective words/s\n",
            "2020-01-16 07:49:07,377 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:07,391 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:07,392 : INFO : EPOCH - 61 : training on 146670 raw words (124189 effective words) took 0.3s, 448123 effective words/s\n",
            "2020-01-16 07:49:07,656 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:07,670 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:07,671 : INFO : EPOCH - 62 : training on 146670 raw words (124166 effective words) took 0.3s, 456675 effective words/s\n",
            "2020-01-16 07:49:07,937 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:07,953 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:07,954 : INFO : EPOCH - 63 : training on 146670 raw words (124092 effective words) took 0.3s, 447361 effective words/s\n",
            "2020-01-16 07:49:08,236 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:08,251 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:08,253 : INFO : EPOCH - 64 : training on 146670 raw words (124346 effective words) took 0.3s, 425290 effective words/s\n",
            "2020-01-16 07:49:08,535 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:08,552 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:08,553 : INFO : EPOCH - 65 : training on 146670 raw words (124072 effective words) took 0.3s, 440063 effective words/s\n",
            "2020-01-16 07:49:08,809 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:08,824 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:08,825 : INFO : EPOCH - 66 : training on 146670 raw words (124115 effective words) took 0.3s, 468851 effective words/s\n",
            "2020-01-16 07:49:09,087 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:09,101 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:09,102 : INFO : EPOCH - 67 : training on 146670 raw words (123952 effective words) took 0.3s, 457225 effective words/s\n",
            "2020-01-16 07:49:09,378 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:09,392 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:09,393 : INFO : EPOCH - 68 : training on 146670 raw words (123955 effective words) took 0.3s, 435114 effective words/s\n",
            "2020-01-16 07:49:09,654 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:09,668 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:09,669 : INFO : EPOCH - 69 : training on 146670 raw words (124125 effective words) took 0.3s, 460319 effective words/s\n",
            "2020-01-16 07:49:09,928 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:09,943 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:09,944 : INFO : EPOCH - 70 : training on 146670 raw words (124124 effective words) took 0.3s, 462337 effective words/s\n",
            "2020-01-16 07:49:10,217 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:10,232 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:10,232 : INFO : EPOCH - 71 : training on 146670 raw words (124015 effective words) took 0.3s, 439043 effective words/s\n",
            "2020-01-16 07:49:10,526 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:10,532 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:10,533 : INFO : EPOCH - 72 : training on 146670 raw words (124148 effective words) took 0.3s, 424176 effective words/s\n",
            "2020-01-16 07:49:10,793 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:10,807 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:10,808 : INFO : EPOCH - 73 : training on 146670 raw words (124169 effective words) took 0.3s, 461860 effective words/s\n",
            "2020-01-16 07:49:11,079 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:11,095 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:11,096 : INFO : EPOCH - 74 : training on 146670 raw words (124184 effective words) took 0.3s, 441386 effective words/s\n",
            "2020-01-16 07:49:11,375 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:11,392 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:11,393 : INFO : EPOCH - 75 : training on 146670 raw words (124089 effective words) took 0.3s, 426142 effective words/s\n",
            "2020-01-16 07:49:11,651 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:11,666 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:11,667 : INFO : EPOCH - 76 : training on 146670 raw words (124008 effective words) took 0.3s, 465195 effective words/s\n",
            "2020-01-16 07:49:11,941 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:11,954 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:11,955 : INFO : EPOCH - 77 : training on 146670 raw words (123922 effective words) took 0.3s, 439272 effective words/s\n",
            "2020-01-16 07:49:12,223 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:12,238 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:12,239 : INFO : EPOCH - 78 : training on 146670 raw words (124135 effective words) took 0.3s, 451108 effective words/s\n",
            "2020-01-16 07:49:12,518 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:12,532 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:12,533 : INFO : EPOCH - 79 : training on 146670 raw words (123940 effective words) took 0.3s, 430634 effective words/s\n",
            "2020-01-16 07:49:12,795 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:12,809 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:12,810 : INFO : EPOCH - 80 : training on 146670 raw words (124161 effective words) took 0.3s, 458651 effective words/s\n",
            "2020-01-16 07:49:13,066 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:13,080 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:13,081 : INFO : EPOCH - 81 : training on 146670 raw words (124072 effective words) took 0.3s, 468261 effective words/s\n",
            "2020-01-16 07:49:13,344 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:13,358 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:13,359 : INFO : EPOCH - 82 : training on 146670 raw words (124175 effective words) took 0.3s, 456578 effective words/s\n",
            "2020-01-16 07:49:13,639 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:13,646 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:13,647 : INFO : EPOCH - 83 : training on 146670 raw words (124012 effective words) took 0.3s, 442203 effective words/s\n",
            "2020-01-16 07:49:13,923 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:13,938 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:13,939 : INFO : EPOCH - 84 : training on 146670 raw words (124048 effective words) took 0.3s, 435149 effective words/s\n",
            "2020-01-16 07:49:14,208 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:14,227 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:14,228 : INFO : EPOCH - 85 : training on 146670 raw words (124047 effective words) took 0.3s, 440120 effective words/s\n",
            "2020-01-16 07:49:14,532 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:14,544 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:14,544 : INFO : EPOCH - 86 : training on 146670 raw words (124186 effective words) took 0.3s, 411197 effective words/s\n",
            "2020-01-16 07:49:14,800 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:14,813 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:14,814 : INFO : EPOCH - 87 : training on 146670 raw words (124133 effective words) took 0.3s, 471929 effective words/s\n",
            "2020-01-16 07:49:15,082 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:15,095 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:15,096 : INFO : EPOCH - 88 : training on 146670 raw words (124246 effective words) took 0.3s, 450055 effective words/s\n",
            "2020-01-16 07:49:15,386 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:15,400 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:15,401 : INFO : EPOCH - 89 : training on 146670 raw words (124198 effective words) took 0.3s, 414827 effective words/s\n",
            "2020-01-16 07:49:15,674 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:15,683 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:15,684 : INFO : EPOCH - 90 : training on 146670 raw words (124082 effective words) took 0.3s, 450970 effective words/s\n",
            "2020-01-16 07:49:15,953 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:15,968 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:15,968 : INFO : EPOCH - 91 : training on 146670 raw words (124112 effective words) took 0.3s, 444643 effective words/s\n",
            "2020-01-16 07:49:16,245 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:16,260 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:16,261 : INFO : EPOCH - 92 : training on 146670 raw words (124014 effective words) took 0.3s, 434144 effective words/s\n",
            "2020-01-16 07:49:16,539 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:16,553 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:16,554 : INFO : EPOCH - 93 : training on 146670 raw words (124142 effective words) took 0.3s, 434184 effective words/s\n",
            "2020-01-16 07:49:16,814 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:16,829 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:16,830 : INFO : EPOCH - 94 : training on 146670 raw words (124170 effective words) took 0.3s, 461195 effective words/s\n",
            "2020-01-16 07:49:17,103 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:17,119 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:17,119 : INFO : EPOCH - 95 : training on 146670 raw words (124150 effective words) took 0.3s, 440488 effective words/s\n",
            "2020-01-16 07:49:17,382 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:17,397 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:17,398 : INFO : EPOCH - 96 : training on 146670 raw words (124110 effective words) took 0.3s, 454783 effective words/s\n",
            "2020-01-16 07:49:17,682 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:17,700 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:17,701 : INFO : EPOCH - 97 : training on 146670 raw words (124276 effective words) took 0.3s, 424123 effective words/s\n",
            "2020-01-16 07:49:17,965 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:17,980 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:17,981 : INFO : EPOCH - 98 : training on 146670 raw words (124197 effective words) took 0.3s, 453962 effective words/s\n",
            "2020-01-16 07:49:18,246 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:18,262 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:18,263 : INFO : EPOCH - 99 : training on 146670 raw words (124157 effective words) took 0.3s, 450472 effective words/s\n",
            "2020-01-16 07:49:18,532 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-01-16 07:49:18,547 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-01-16 07:49:18,548 : INFO : EPOCH - 100 : training on 146670 raw words (124063 effective words) took 0.3s, 443704 effective words/s\n",
            "2020-01-16 07:49:18,549 : INFO : training on a 14667000 raw words (12410675 effective words) took 28.8s, 431490 effective words/s\n",
            "2020-01-16 07:49:18,552 : INFO : Vocabulary size: 27250\n",
            "2020-01-16 07:49:18,553 : INFO : Word2Vec trained\n",
            "2020-01-16 07:49:18,554 : INFO : Fit LabelEncoder\n",
            "2020-01-16 07:49:18,565 : INFO : Fit Tokenizer\n",
            "2020-01-16 07:49:18,792 : INFO : Number of unique words: 27251\n",
            "2020-01-16 07:49:18,793 : INFO : Create Embedding matrix\n",
            "2020-01-16 07:49:23,836 : INFO : Embedding matrix: (27251, 300)\n",
            "2020-01-16 07:49:23,837 : INFO : Build Keras model\n",
            "2020-01-16 07:49:23,841 : INFO : x_train shape: (7991, 1000)\n",
            "2020-01-16 07:49:23,844 : INFO : y_train shape: (7991, 2)\n",
            "2020-01-16 07:49:24,800 : INFO : None\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1335: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n",
            "2020-01-16 07:49:24,801 : INFO : Fit Keras model\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 1000, 300)         8175300   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 512)               1665024   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 9,841,350\n",
            "Trainable params: 1,666,050\n",
            "Non-trainable params: 8,175,300\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "7991/7991 [==============================] - 90s 11ms/step - loss: 0.4156 - acc: 0.8079\n",
            "Epoch 2/5\n",
            "7991/7991 [==============================] - 89s 11ms/step - loss: 0.3300 - acc: 0.8562\n",
            "Epoch 3/5\n",
            "7991/7991 [==============================] - 89s 11ms/step - loss: 0.2964 - acc: 0.8761\n",
            "Epoch 4/5\n",
            "7991/7991 [==============================] - 89s 11ms/step - loss: 0.2954 - acc: 0.8730\n",
            "Epoch 5/5\n",
            "7991/7991 [==============================] - 89s 11ms/step - loss: 0.3241 - acc: 0.8560\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-01-16 07:56:51,363 : INFO : Done\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2664/2664 [==============================] - 47s 18ms/step\n",
            "Confusion Matrix:  [[1194  153]\n",
            " [ 227 1090]]\n",
            "LABEL: negative\n",
            "TEXT :  ilk filmden daha kötu hayal kirikligina ugradim \n",
            "/n============================================\n",
            "PREDICTION: {'label': 'negative', 'confidence': 0.7479504346847534, 'elapsed_time': 0.5456364154815674}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}